{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from nps.nps import NPsDecoder\n",
    "\n",
    "z = np.load(\"./nps/latent_vectors/alum-bronze_latentVector.npy\")\n",
    "z = torch.from_numpy(z)\n",
    "z = z.to('cuda').float()\n",
    "\n",
    "module = NPsDecoder(z[0], z[1])\n",
    "module.load_state_dict(torch.load('nps/model/decoder.pt'))\n",
    "module = module.to('cuda').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not open file\n",
      "torch.Size([1, 129600, 4])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() takes 4 positional arguments but 6 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 49\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(x_grid\u001b[38;5;241m.\u001b[39mshape) \n\u001b[0;32m     45\u001b[0m gt_fixed_h \u001b[38;5;241m=\u001b[39m fit_brdf\u001b[38;5;241m.\u001b[39mhalf_diff_look_up_brdf(\n\u001b[0;32m     46\u001b[0m     repeated_array, plane1_theta_h, plane2_theta_h, use_interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     47\u001b[0m )\n\u001b[1;32m---> 49\u001b[0m pred_fixed_h \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m pred_fixed_h \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mpostprocess(pred_fixed_h)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     51\u001b[0m pred_fixed_h\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(pred_fixed_h,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32ms:\\Anaconda\\envs\\torch21\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32ms:\\Anaconda\\envs\\torch21\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() takes 4 positional arguments but 6 were given"
     ]
    }
   ],
   "source": [
    "## test the learned model and visualize the results\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "filename = \"alum-bronze.binary\"\n",
    "model_path = \"be_simple_mlp_\"+ filename + \".pth\"\n",
    "\n",
    "fit_brdf = MeasuredBRDF(filename)\n",
    "test_brdf = MeasuredBRDF(\"nps/test.binary\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "n_split = 360\n",
    "\n",
    "theta_h = np.linspace(0, np.pi / 2, n_split)\n",
    "theta_d = np.linspace(0, np.pi / 2, n_split)\n",
    "phi_d = np.linspace(0, np.pi, n_split)\n",
    "\n",
    "plane1_phi_d, plane2_phi_d = np.meshgrid(theta_h, theta_d)\n",
    "plane1_theta_d, plane2_theta_d = np.meshgrid(theta_h, phi_d)\n",
    "plane1_theta_h, plane2_theta_h = np.meshgrid(theta_d, phi_d)\n",
    "\n",
    "plane1_phi_d, plane2_phi_d = plane1_phi_d.flatten(), plane2_phi_d.flatten()\n",
    "plane1_theta_d, plane2_theta_d = plane1_theta_d.flatten(), plane2_theta_d.flatten()\n",
    "plane1_theta_h, plane2_theta_h = plane1_theta_h.flatten(), plane2_theta_h.flatten()\n",
    "\n",
    "\n",
    "fixed_angle = \"np.pi * 0.2\"\n",
    "repeated_array = np.full(n_split**2, eval(fixed_angle))\n",
    "\n",
    "\n",
    "\n",
    "theta_h_in = torch.from_numpy(repeated_array).float().to(device)\n",
    "theta_d_in = torch.from_numpy(plane1_theta_h).float().to(device)\n",
    "phi_d_in = torch.from_numpy(plane2_theta_h).float().to(device)\n",
    "conca_in_fixed_h = torch.stack([theta_h_in, theta_d_in, phi_d_in], dim=1)\n",
    "\n",
    "gt_fixed_h = fit_brdf.half_diff_look_up_brdf(\n",
    "    repeated_array, plane1_theta_h, plane2_theta_h, use_interpolation=False\n",
    ")\n",
    "\n",
    "pred_fixed_h = module(phi_d_in, theta_h_in, theta_d_in).detach().cpu().numpy()\n",
    "pred_fixed_h= np.clip(pred_fixed_h,0,None)\n",
    "gt_fixed_h = gt_fixed_h.reshape(n_split, n_split,3)\n",
    "pred_fixed_h = pred_fixed_h.reshape(n_split, n_split,3)\n",
    "\n",
    "#visualize R channel\n",
    "\n",
    "R_pred = pred_fixed_h[:,:,0]\n",
    "R_gt = gt_fixed_h[:,:,0]\n",
    "vmin = R_pred.min()\n",
    "vmax = R_pred.max()\n",
    "levels = np.linspace(vmin, vmax, 100)\n",
    "plt.figure(figsize=(16, 16))\n",
    "# plt.subplot(1, 2, 1)\n",
    "\n",
    "plt.contourf(theta_d, phi_d, R_pred, cmap='viridis', levels=levels,vmin=vmin, vmax=vmax)\n",
    "plt.colorbar(label='pred_fixed_h value')\n",
    "plt.xlabel('theta_d (x)')\n",
    "plt.ylabel('phi_d (y)')\n",
    "plt.title('2D Function Visualization (pred) fixed_angle = '+ fixed_angle)\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.contourf(theta_d, phi_d, R_gt, cmap='viridis', levels=levels,vmin=vmin, vmax=vmax)\n",
    "# plt.colorbar(label='gt_fixed_h value')\n",
    "# plt.xlabel('theta_d (x)')\n",
    "# plt.ylabel('phi_d (y)')\n",
    "# plt.title('2D Function Visualization (gt) fixed_angle = '+fixed_angle)\n",
    "# plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
